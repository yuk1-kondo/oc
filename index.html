<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Optical Camouflage</title>
  <style>
    html, body { margin:0; padding:0; background:#111; color:#eee; font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; }
    .wrap { display:grid; grid-template-rows:auto 1fr; height:100vh; }
    .bar {
      display:flex; gap:12px; align-items:center;
      padding:10px 12px; background:#1b1b1b; border-bottom:1px solid #2a2a2a;
      flex-wrap: wrap;
    }
    button, input[type="range"] { accent-color: #8bd; }
    button {
      background:#2a2a2a; color:#eee; border:1px solid #3a3a3a; border-radius:10px;
      padding:8px 12px; cursor:pointer;
    }
    button:hover { background:#333; }
    label { display:flex; align-items:center; gap:8px; font-size:14px; opacity:.9; }
    .stage { position:relative; width:100%; height:100%; display:grid; place-items:center; }
    canvas { width: min(100vw, 1100px); height:auto; border-radius:14px; box-shadow: 0 10px 35px rgba(0,0,0,.45); }
    video { display:none; }
    small { opacity:.75; }
  </style>

  <!-- MediaPipe Selfie Segmentation (CDN) -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js"></script>
</head>

<body>
  <div class="wrap">
    <div class="bar">
      <button id="btnStart">Start</button>
      <button id="btnFreeze" disabled>Freeze BG</button>
      <button id="btnUnfreeze" disabled>Unfreeze</button>

      <label>
        Cloak
        <input id="mix" type="range" min="0" max="1" step="0.01" value="0.85" />
        <small id="mixVal">0.85</small>
      </label>

      <label>
        Edge Blur
        <input id="edge" type="range" min="0" max="10" step="0.1" value="3.0" />
        <small id="edgeVal">3.0</small>
      </label>

      <label>
        Warp
        <input id="warp" type="range" min="0" max="12" step="0.1" value="4.0" />
        <small id="warpVal">4.0</small>
      </label>

      <small>HTTPS required</small>
    </div>

    <div class="stage">
      <video id="video" playsinline></video>
      <canvas id="gl"></canvas>
    </div>
  </div>

<script>
(async () => {
  const video = document.getElementById('video');
  const canvas = document.getElementById('gl');
  const btnStart = document.getElementById('btnStart');
  const btnFreeze = document.getElementById('btnFreeze');
  const btnUnfreeze = document.getElementById('btnUnfreeze');

  const mixEl = document.getElementById('mix');
  const edgeEl = document.getElementById('edge');
  const warpEl = document.getElementById('warp');
  const mixVal = document.getElementById('mixVal');
  const edgeVal = document.getElementById('edgeVal');
  const warpVal = document.getElementById('warpVal');

  function syncUI() {
    mixVal.textContent = (+mixEl.value).toFixed(2);
    edgeVal.textContent = (+edgeEl.value).toFixed(1);
    warpVal.textContent = (+warpEl.value).toFixed(1);
  }
  [mixEl, edgeEl, warpEl].forEach(el => el.addEventListener('input', syncUI));
  syncUI();

  // ---------- WebGL2 setup ----------
  const gl = canvas.getContext('webgl2', { premultipliedAlpha:false, antialias:false });
  if (!gl) {
    alert('WebGL2 が使えません（Safari旧版など）。');
    return;
  }

  const vsSrc = `#version 300 es
  precision highp float;
  in vec2 a_pos;
  out vec2 v_uv;
  void main() {
    v_uv = (a_pos + 1.0) * 0.5;
    gl_Position = vec4(a_pos, 0.0, 1.0);
  }`;

  // 人物領域(=mask)にだけ多段合成した「背景っぽいもの」を描く
  // maskはMediaPipeのsegmentationMask（人物=1に近い）
  const fsSrc = `#version 300 es
  precision highp float;
  in vec2 v_uv;
  out vec4 outColor;

  uniform sampler2D u_now;     // current frame
  uniform sampler2D u_p1;      // past 1
  uniform sampler2D u_p2;      // past 2
  uniform sampler2D u_p3;      // past 3
  uniform sampler2D u_mask;    // segmentation mask (person ~1)
  uniform sampler2D u_freeze;  // frozen background (optional)

  uniform vec2  u_texel;       // 1/width, 1/height
  uniform float u_mix;         // cloak strength
  uniform float u_edge;        // edge blur
  uniform float u_warp;        // distortion strength
  uniform float u_useFreeze;   // 1 when frozen

  // cheap blur on mask to soften edges
  float blurMask(vec2 uv, float r) {
    // 9-tap box-ish blur (fast & simple)
    float s = 0.0;
    float w = 0.0;
    for (int y=-1; y<=1; y++) {
      for (int x=-1; x<=1; x++) {
        vec2 o = vec2(float(x), float(y)) * u_texel * r;
        float m = texture(u_mask, uv + o).r;
        s += m;
        w += 1.0;
      }
    }
    return s / w;
  }

  vec3 sampleWarped(sampler2D tex, vec2 uv, float t, float amp) {
    // subtle wave distortion
    float wx = sin((uv.y * 12.0 + t*1.7)) * amp;
    float wy = cos((uv.x * 10.0 - t*1.3)) * amp;
    vec2 duv = uv + vec2(wx, wy) * u_texel;
    return texture(tex, duv).rgb;
  }

  void main() {
    float t = float(gl_FragCoord.x + gl_FragCoord.y) * 0.0; // deterministic base
    vec3 now = texture(u_now, v_uv).rgb;

    // edge soften + slight dilate by boosting radius
    float m = blurMask(v_uv, max(0.0, u_edge));
    // Make mask more binary-ish but still soft
    m = smoothstep(0.35, 0.75, m);

    // Multi-layer "cloak" from frozen bg + past frames
    // Layer offsets create "multi-stage" diagonal feel
    float amp = u_warp * 0.35;

    vec2 o1 = vec2( 1.5, -1.0) * u_texel * (2.0 + u_warp);
    vec2 o2 = vec2(-2.0,  1.2) * u_texel * (3.0 + u_warp);
    vec2 o3 = vec2( 2.2,  2.0) * u_texel * (4.0 + u_warp);

    // choose base background source
    vec3 baseBg = now;
    if (u_useFreeze > 0.5) {
      baseBg = texture(u_freeze, v_uv).rgb;
    }

    // Past layers (like time-lag "shimmers")
    vec3 p1 = sampleWarped(u_p1, v_uv + o1, 1.0, amp);
    vec3 p2 = sampleWarped(u_p2, v_uv + o2, 2.0, amp * 1.2);
    vec3 p3 = sampleWarped(u_p3, v_uv + o3, 3.0, amp * 1.4);

    // Layer weights (sum <= 1)
    vec3 cloak = baseBg * 0.55 + p1 * 0.23 + p2 * 0.14 + p3 * 0.08;

    // subtle edge highlight (optional: makes "refraction" feel)
    float edge = smoothstep(0.30, 0.55, m) - smoothstep(0.55, 0.80, m);
    cloak += edge * 0.06;

    // apply only on person area
    float k = clamp(u_mix, 0.0, 1.0);
    vec3 outRgb = mix(now, cloak, m * k);

    outColor = vec4(outRgb, 1.0);
  }`;

  function compile(type, src) {
    const s = gl.createShader(type);
    gl.shaderSource(s, src);
    gl.compileShader(s);
    if (!gl.getShaderParameter(s, gl.COMPILE_STATUS)) {
      console.error(gl.getShaderInfoLog(s));
      throw new Error('Shader compile failed');
    }
    return s;
  }
  function link(vs, fs) {
    const p = gl.createProgram();
    gl.attachShader(p, vs);
    gl.attachShader(p, fs);
    gl.linkProgram(p);
    if (!gl.getProgramParameter(p, gl.LINK_STATUS)) {
      console.error(gl.getProgramInfoLog(p));
      throw new Error('Program link failed');
    }
    return p;
  }

  const prog = link(compile(gl.VERTEX_SHADER, vsSrc), compile(gl.FRAGMENT_SHADER, fsSrc));
  gl.useProgram(prog);

  // Fullscreen quad
  const quad = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, quad);
  gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
    -1, -1,  1, -1, -1,  1,
    -1,  1,  1, -1,  1,  1
  ]), gl.STATIC_DRAW);

  const aPos = gl.getAttribLocation(prog, 'a_pos');
  gl.enableVertexAttribArray(aPos);
  gl.vertexAttribPointer(aPos, 2, gl.FLOAT, false, 0, 0);

  // uniforms
  const U = {
    now: gl.getUniformLocation(prog, 'u_now'),
    p1: gl.getUniformLocation(prog, 'u_p1'),
    p2: gl.getUniformLocation(prog, 'u_p2'),
    p3: gl.getUniformLocation(prog, 'u_p3'),
    mask: gl.getUniformLocation(prog, 'u_mask'),
    freeze: gl.getUniformLocation(prog, 'u_freeze'),
    texel: gl.getUniformLocation(prog, 'u_texel'),
    mix: gl.getUniformLocation(prog, 'u_mix'),
    edge: gl.getUniformLocation(prog, 'u_edge'),
    warp: gl.getUniformLocation(prog, 'u_warp'),
    useFreeze: gl.getUniformLocation(prog, 'u_useFreeze')
  };

  function makeTex(unit, uniformLoc) {
    const tex = gl.createTexture();
    gl.activeTexture(gl.TEXTURE0 + unit);
    gl.bindTexture(gl.TEXTURE_2D, tex);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.uniform1i(uniformLoc, unit);
    return tex;
  }

  // texture units mapping
  const TEX = {
    now: makeTex(0, U.now),
    p1: makeTex(1, U.p1),
    p2: makeTex(2, U.p2),
    p3: makeTex(3, U.p3),
    mask: makeTex(4, U.mask),
    freeze: makeTex(5, U.freeze)
  };

  // ring buffer for past frames (store canvases)
  const RING = {
    size: 24,          // keep 24 frames history
    idx: 0,
    frames: []         // each is an Offscreen/Canvas
  };
  for (let i=0; i<RING.size; i++) {
    const c = document.createElement('canvas');
    c.width = 2; c.height = 2;
    RING.frames.push(c);
  }

  // work canvases
  const grab = document.createElement('canvas'); // current frame buffer
  const grabCtx = grab.getContext('2d', { willReadFrequently:false });

  const freezeCanvas = document.createElement('canvas');
  const freezeCtx = freezeCanvas.getContext('2d', { willReadFrequently:false });
  let useFreeze = 0;

  // ---------- MediaPipe Selfie Segmentation ----------
  let segmentationMaskCanvas = document.createElement('canvas'); // will be drawn by MediaPipe
  let segReady = false;

  const selfieSeg = new SelfieSegmentation({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`
  });
  selfieSeg.setOptions({
    modelSelection: 1, // 0: general, 1: landscape (環境向けで安定しやすいことが多い)
  });
  selfieSeg.onResults((results) => {
    // results.segmentationMask is an HTMLCanvasElement-like
    // We copy it into our own canvas to use as a texture source.
    const m = results.segmentationMask;
    if (!m) return;

    if (segmentationMaskCanvas.width !== m.width || segmentationMaskCanvas.height !== m.height) {
      segmentationMaskCanvas.width = m.width;
      segmentationMaskCanvas.height = m.height;
    }
    const ctx = segmentationMaskCanvas.getContext('2d');
    ctx.clearRect(0,0,segmentationMaskCanvas.width, segmentationMaskCanvas.height);
    ctx.drawImage(m, 0, 0);
    segReady = true;
  });

  // ---------- camera & main loop ----------
  let running = false;

  async function start() {
    if (running) return;
    running = true;

    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: "user", width: { ideal: 1280 }, height: { ideal: 720 } },
      audio: false
    });
    video.srcObject = stream;
    await video.play();

    // resize canvases to video
    const w = video.videoWidth;
    const h = video.videoHeight;

    // output canvas size (keep original res for best mask edges)
    canvas.width = w;
    canvas.height = h;

    grab.width = w; grab.height = h;
    freezeCanvas.width = w; freezeCanvas.height = h;

    // init ring canvases sizes
    for (const c of RING.frames) { c.width = w; c.height = h; }

    gl.viewport(0, 0, w, h);
    gl.uniform2f(U.texel, 1 / w, 1 / h);

    btnFreeze.disabled = false;
    btnUnfreeze.disabled = false;

    // warm up: fill ring with current
    for (let i=0; i<RING.size; i++) {
      const c = RING.frames[i];
      const cctx = c.getContext('2d');
      cctx.drawImage(video, 0, 0, w, h);
    }

    requestAnimationFrame(loop);
  }

  function uploadToTex(tex, source) {
    gl.bindTexture(gl.TEXTURE_2D, tex);
    // Use texImage2D each time (simple). For perf, texSubImage2D also works.
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, source);
  }

  // pick past frames by delays (in frames)
  function getPastCanvas(delay) {
    let i = (RING.idx - delay) % RING.size;
    if (i < 0) i += RING.size;
    return RING.frames[i];
  }

  let frameCount = 0;
  async function loop() {
    if (!running) return;

    const w = canvas.width, h = canvas.height;

    // 1) grab current frame into grab canvas
    grabCtx.drawImage(video, 0, 0, w, h);

    // 2) push into ring buffer
    {
      const c = RING.frames[RING.idx];
      const cctx = c.getContext('2d');
      cctx.drawImage(grab, 0, 0);
      RING.idx = (RING.idx + 1) % RING.size;
    }

    // 3) run segmentation occasionally or every frame
    //   - every frame is best quality, but heavy on low-end devices.
    //   - if you want lighter, do: if (frameCount % 2 === 0) await...
    await selfieSeg.send({ image: grab });
    frameCount++;

    // 4) upload textures
    gl.activeTexture(gl.TEXTURE0);
    uploadToTex(TEX.now, grab);

    // delays: 6, 12, 18 frames (30fpsなら約200/400/600ms)
    gl.activeTexture(gl.TEXTURE1);
    uploadToTex(TEX.p1, getPastCanvas(6));

    gl.activeTexture(gl.TEXTURE2);
    uploadToTex(TEX.p2, getPastCanvas(12));

    gl.activeTexture(gl.TEXTURE3);
    uploadToTex(TEX.p3, getPastCanvas(18));

    gl.activeTexture(gl.TEXTURE4);
    if (segReady) uploadToTex(TEX.mask, segmentationMaskCanvas);
    else uploadToTex(TEX.mask, grab); // fallback (意味は薄いがクラッシュ回避)

    gl.activeTexture(gl.TEXTURE5);
    uploadToTex(TEX.freeze, freezeCanvas);

    // 5) uniforms from UI
    gl.uniform1f(U.mix, parseFloat(mixEl.value));
    gl.uniform1f(U.edge, parseFloat(edgeEl.value));
    gl.uniform1f(U.warp, parseFloat(warpEl.value));
    gl.uniform1f(U.useFreeze, useFreeze);

    // 6) draw
    gl.drawArrays(gl.TRIANGLES, 0, 6);

    requestAnimationFrame(loop);
  }

  btnStart.addEventListener('click', () => start().catch(err => {
    console.error(err);
    alert('開始に失敗: ' + err.message);
  }));

  btnFreeze.addEventListener('click', () => {
    if (!running) return;
    freezeCtx.drawImage(video, 0, 0, freezeCanvas.width, freezeCanvas.height);
    useFreeze = 1;
  });

  btnUnfreeze.addEventListener('click', () => {
    useFreeze = 0;
  });

})();
</script>
</body>
</html>
